{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from pygments.lexers import get_lexer_by_name\n",
    "from pygments.token import Token\n",
    "\n",
    "from math import log2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data and Split into Train and Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File Name</th>\n",
       "      <th>Method Name</th>\n",
       "      <th>Method Code XML</th>\n",
       "      <th>Method Java</th>\n",
       "      <th>Method Java Formatted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./GitHub Repos/twitter4j/twitter4j/twitter4j-c...</td>\n",
       "      <td>createRelationshipList</td>\n",
       "      <td>&lt;function pos:start=\"81:5\" pos:end=\"104:5\"&gt;&lt;ty...</td>\n",
       "      <td>static   ResponseList &lt; Relationship &gt;   creat...</td>\n",
       "      <td>static ResponseList&lt;Relationship&gt; createRelati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./GitHub Repos/twitter4j/twitter4j/twitter4j-c...</td>\n",
       "      <td>isSourceBlockingTarget</td>\n",
       "      <td>&lt;function pos:start=\"117:5\" pos:end=\"120:5\"&gt;&lt;a...</td>\n",
       "      <td>@ Override \\n public   boolean   isSourceBlock...</td>\n",
       "      <td>@Override\\n  public boolean isSourceBlockingTa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./GitHub Repos/twitter4j/twitter4j/twitter4j-c...</td>\n",
       "      <td>isSourceFollowingTarget</td>\n",
       "      <td>&lt;function pos:start=\"132:5\" pos:end=\"135:5\"&gt;&lt;a...</td>\n",
       "      <td>@ Override \\n public   boolean   isSourceFollo...</td>\n",
       "      <td>@Override\\n  public boolean isSourceFollowingT...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           File Name              Method Name  \\\n",
       "0  ./GitHub Repos/twitter4j/twitter4j/twitter4j-c...   createRelationshipList   \n",
       "1  ./GitHub Repos/twitter4j/twitter4j/twitter4j-c...   isSourceBlockingTarget   \n",
       "2  ./GitHub Repos/twitter4j/twitter4j/twitter4j-c...  isSourceFollowingTarget   \n",
       "\n",
       "                                     Method Code XML  \\\n",
       "0  <function pos:start=\"81:5\" pos:end=\"104:5\"><ty...   \n",
       "1  <function pos:start=\"117:5\" pos:end=\"120:5\"><a...   \n",
       "2  <function pos:start=\"132:5\" pos:end=\"135:5\"><a...   \n",
       "\n",
       "                                         Method Java  \\\n",
       "0  static   ResponseList < Relationship >   creat...   \n",
       "1  @ Override \\n public   boolean   isSourceBlock...   \n",
       "2  @ Override \\n public   boolean   isSourceFollo...   \n",
       "\n",
       "                               Method Java Formatted  \n",
       "0  static ResponseList<Relationship> createRelati...  \n",
       "1  @Override\\n  public boolean isSourceBlockingTa...  \n",
       "2  @Override\\n  public boolean isSourceFollowingT...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_dataset = pd.read_csv(\"student_dataset.csv\")\n",
    "student_dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 100 methods to serve as the test set\n",
    "test_set = student_dataset.sample(n=100, random_state=12)\n",
    "\n",
    "# Remove the methods from the training set\n",
    "student_training_set = student_dataset.drop(test_set.index).reset_index(drop=True)\n",
    "\n",
    "# Select 100 methods for the evaluation set\n",
    "evaluation_set = student_dataset.sample(n=100, random_state=12)\n",
    "\n",
    "# Remove the methods from the training set\n",
    "student_training_set = student_dataset.drop(evaluation_set.index).reset_index(drop=True)\n",
    "\n",
    "# Reset index of test set\n",
    "test_set = test_set.reset_index()\n",
    "\n",
    "# Reset index of evaluation set\n",
    "evaluation_set = evaluation_set.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "\n",
    "class N_Gram_Code_Model:\n",
    "    def __init__(self, N: int):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            N (int): The number of tokens the model uses to make predictions\n",
    "        \"\"\"\n",
    "        self.N = N\n",
    "\n",
    "        # The model is stored as a defaultdict of Counters\n",
    "        # The defaultdict maps tuples of tokens to the counters of tokens that follow them\n",
    "        # The Counters act as dicts that map tokens that follow tuples to the number of times that token occurs after the first sequence of tokens\n",
    "        self.model = defaultdict(Counter)\n",
    "\n",
    "        # The total number of context windows of length self.N - 1 that the model has encountered\n",
    "        self.total_strings_seen = 0\n",
    "\n",
    "\n",
    "\n",
    "    def train_model(self, training_set: pd.DataFrame, method_column: str = \"Method Java Formatted\"):\n",
    "\n",
    "        lexer = get_lexer_by_name(\"Java\")\n",
    "\n",
    "        # Keeps track of how many methods were skipped because they were too short\n",
    "        skipped_methods = 0\n",
    "\n",
    "        for i, method in enumerate(training_set[method_column].array):\n",
    "            # if i % 10000 == 0 and i != 0:\n",
    "            #     print(f\"Processed Method {i}\")\n",
    "\n",
    "            # Tokenize method - Add <START> and <END> to help model learn where method boundaries are\n",
    "            tokens = [\"<START>\"] + list(lexer.get_tokens(method)) + [\"<END>\"]\n",
    "\n",
    "            # # If the method doesn't have enough tokens, skip it\n",
    "            if len(tokens) <= self.N:\n",
    "                # print(\"Warning, method too short to analyze\")\n",
    "                skipped_methods += 1\n",
    "                continue\n",
    "            \n",
    "            # For each string of N concurrent tokens, see what token follows\n",
    "            for i in range(len(tokens)-(self.N-1)):\n",
    "                key = tuple(token[1] for token in tokens[i:i+(self.N-1)])\n",
    "\n",
    "                # Update the counter for this token occurring after this sequence of N-1 tokens\n",
    "                self.model[key][tokens[i+self.N-1][1]] += 1\n",
    "\n",
    "        self.total_strings_seen = sum(counter.total() for counter in self.model.values())\n",
    "        \n",
    "        print(f\"Number of methods that were too short to analyze: {skipped_methods}\")\n",
    "\n",
    "\n",
    "\n",
    "    def make_prediction(self, code: str) -> str:\n",
    "        \"\"\"\n",
    "        Given the input code, returns the most likely token to appear after the given string\n",
    "\n",
    "        If the model cannot predict any tokens <NULL> will be returned\n",
    "        \"\"\"\n",
    "        tokens = []\n",
    "\n",
    "        # Since <START> is not a token we want the Java lexer to process, remove it if present\n",
    "        if code.startswith(\"<START>\"):\n",
    "            tokens.append(\"<START>\")\n",
    "            code = code[8:]\n",
    "        \n",
    "        # If we're at the end of the method or if there is an unknown token at the end, the model cannot make a prediction\n",
    "        if code.endswith(\"<END>\") or code.endswith(\"<NULL>\"):\n",
    "            return \"<NULL>\"\n",
    "\n",
    "        lexer = get_lexer_by_name(\"Java\")\n",
    "        tokens = tokens + list(lexer.get_tokens(code))\n",
    "\n",
    "        if tokens[-1][1] == \"\\n\" and code[-1] != \"\\n\":\n",
    "            # Pygments likes to add new lines to my strings, which I don't want because it changes the predictions\n",
    "            tokens = tokens[:-1]\n",
    "\n",
    "        if len(tokens) < self.N -1:\n",
    "            print(\"Error: Input string not long enough to predict new token\")\n",
    "            return \"<NULL>\"\n",
    "\n",
    "        context = tuple(token[1] for token in tokens[-(self.N-1):])\n",
    "\n",
    "\n",
    "        # Predict the most likely token - if multiple tokens have the same likelihood, the first one will be chosen\n",
    "        predicted_token = self.model[context].most_common(1)\n",
    "\n",
    "        # Return <NULL> if the model has not seen this context\n",
    "        if len(predicted_token) == 0:\n",
    "            return \"<NULL>\"\n",
    "        \n",
    "        # Now we are guaranteed to have a result\n",
    "        return predicted_token[0][0]\n",
    "\n",
    "\n",
    "\n",
    "    def get_perplexity(self, code: str) -> float:\n",
    "        \"\"\"\n",
    "        Computes the perplexity of the model given the input code\n",
    "        \"\"\"\n",
    "\n",
    "        tokens = []\n",
    "        end_token = []\n",
    "\n",
    "        # Since <START> is not a token we want the Java lexer to process, remove it if present\n",
    "        if code.startswith(\"<START>\"):\n",
    "            tokens.append((\"START\", \"<START>\"))\n",
    "            code = code[8:]\n",
    "        \n",
    "        # If we're at the end of the method, strip off the <END> for the lexer\n",
    "        if code.endswith(\"<END>\"):\n",
    "            end_token.append((\"End\", \"<END>\"))\n",
    "            code = code[:-7]\n",
    "\n",
    "        lexer = get_lexer_by_name(\"Java\")\n",
    "        tokens = tokens + list(lexer.get_tokens(code)) + end_token\n",
    "\n",
    "        if tokens[-1][1] == \"\\n\" and code[-1] != \"\\n\":\n",
    "            # Pygments likes to add new lines to my strings, which I don't want because it changes the predictions\n",
    "            tokens = tokens[:-1]\n",
    "\n",
    "        if len(tokens) < self.N -1:\n",
    "            print(\"Error: Input string not long enough to predict new token\")\n",
    "            return \"<NULL>\"\n",
    "        \n",
    "        total_log_probability = 0.0\n",
    "        \n",
    "        for i in range(len(tokens) - self.N + 1):\n",
    "\n",
    "            context = tuple(token[1] for token in tokens[i:i+(self.N-1)])\n",
    "\n",
    "            # Retrieve the Counter from the dict\n",
    "            potential_tokens = self.model[context]\n",
    "\n",
    "            if len(potential_tokens) == 0:\n",
    "                # If the model has never seen this context before, add a small value since probability shouldn't be 0\n",
    "                probability = 1e-7\n",
    "\n",
    "            else:\n",
    "                next_token = tokens[i+self.N-1][1]\n",
    "                probability = max(potential_tokens[next_token] / potential_tokens.total(), 1e-7)\n",
    "            \n",
    "            total_log_probability += log2(probability)\n",
    "\n",
    "        total_perplexity = 2 ** (-total_log_probability / (len(tokens) - self.N + 1))\n",
    "        \n",
    "        return total_perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SELECT STUDENT MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model with N = 3\n",
      "Number of methods that were too short to analyze: 0\n",
      "\n",
      "\n",
      "Training Model with N = 5\n",
      "Number of methods that were too short to analyze: 0\n",
      "\n",
      "\n",
      "Training Model with N = 7\n",
      "Number of methods that were too short to analyze: 0\n",
      "\n",
      "\n",
      "Training Model with N = 9\n",
      "Number of methods that were too short to analyze: 0\n",
      "\n",
      "\n",
      "Training Model with N = 11\n",
      "Number of methods that were too short to analyze: 0\n",
      "\n",
      "\n",
      "Training Model with N = 13\n",
      "Number of methods that were too short to analyze: 0\n",
      "\n",
      "\n",
      "[[<__main__.N_Gram_Code_Model object at 0x379ee8c20>, 38.86954648826244], [<__main__.N_Gram_Code_Model object at 0x3b0035090>, 5582.823142147847], [<__main__.N_Gram_Code_Model object at 0x3b0035310>, 170877.53428005692], [<__main__.N_Gram_Code_Model object at 0x377ba1cd0>, 358494.08111486735], [<__main__.N_Gram_Code_Model object at 0x377ba23f0>, 725892.3668465437], [<__main__.N_Gram_Code_Model object at 0x32820dc70>, 1248740.1487453976]]\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "for i in range(3,15,2):\n",
    "    print(f\"Training Model with N = {i}\")\n",
    "    model = N_Gram_Code_Model(i)\n",
    "    model.train_model(student_training_set)\n",
    "    # Use evaluation set to evaluate the model\n",
    "    perplexity = sum([model.get_perplexity(code) for code in evaluation_set[\"Method Java Formatted\"].array]) / len(evaluation_set)\n",
    "    models.append([model, perplexity])\n",
    "    print(f\"Perplexity: {perplexity}\\n\")\n",
    "\n",
    "models.sort(key=lambda m: m[1])\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "best_model = models[0][0]\n",
    "print(best_model.N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INSTRUCTOR DATA SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method Java</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>boolean function ( ) { return isParsed ; }\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>File function ( ) { return libraryFile ; }\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>void function ( Directory arg0 , Collection &lt; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>byte [ ] function ( Class &lt; ? &gt; arg0 , Configu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>void function ( Binder arg0 ) { EventBus loc0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>void function ( ) { synchronized ( this ) { th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>String function ( ) { return this . server ; }\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>int function ( int arg0 ) { final int loc0 = M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>String function ( IFileSystemPath arg0 ) { ret...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>void function ( String arg0 , String arg1 ) { ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Method Java\n",
       "0           boolean function ( ) { return isParsed ; }\\n\n",
       "1           File function ( ) { return libraryFile ; }\\n\n",
       "2      void function ( Directory arg0 , Collection < ...\n",
       "3      byte [ ] function ( Class < ? > arg0 , Configu...\n",
       "4      void function ( Binder arg0 ) { EventBus loc0 ...\n",
       "...                                                  ...\n",
       "99995  void function ( ) { synchronized ( this ) { th...\n",
       "99996   String function ( ) { return this . server ; }\\n\n",
       "99997  int function ( int arg0 ) { final int loc0 = M...\n",
       "99998  String function ( IFileSystemPath arg0 ) { ret...\n",
       "99999  void function ( String arg0 , String arg1 ) { ...\n",
       "\n",
       "[100000 rows x 1 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"training.txt\", \"r\") as instructor_file:\n",
    "    instructor_data = pd.DataFrame(instructor_file.readlines(), columns=[\"Method Java\"])\n",
    "instructor_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model with N = 3\n",
      "Number of methods that were too short to analyze: 0\n",
      "Perplexity: 1715719.9194230684\n",
      "\n",
      "Training Model with N = 5\n",
      "Number of methods that were too short to analyze: 0\n",
      "Perplexity: 7462017.7141283\n",
      "\n",
      "Training Model with N = 7\n",
      "Number of methods that were too short to analyze: 0\n",
      "Perplexity: 9587695.196506225\n",
      "\n",
      "Training Model with N = 9\n",
      "Number of methods that were too short to analyze: 0\n",
      "Perplexity: 9925968.679919245\n",
      "\n",
      "Training Model with N = 11\n",
      "Number of methods that were too short to analyze: 0\n",
      "Perplexity: 9999999.999999948\n",
      "\n",
      "Training Model with N = 13\n",
      "Number of methods that were too short to analyze: 0\n",
      "Perplexity: 9999999.999999948\n",
      "\n",
      "Training Model with N = 15\n",
      "Number of methods that were too short to analyze: 819\n",
      "Perplexity: 9999999.999999948\n",
      "\n",
      "[[<__main__.N_Gram_Code_Model object at 0x379ee8c20>, 38.86954648826244], [<__main__.N_Gram_Code_Model object at 0x3b0035090>, 5582.823142147847], [<__main__.N_Gram_Code_Model object at 0x3b0035310>, 170877.53428005692], [<__main__.N_Gram_Code_Model object at 0x377ba1cd0>, 358494.08111486735], [<__main__.N_Gram_Code_Model object at 0x377ba23f0>, 725892.3668465437], [<__main__.N_Gram_Code_Model object at 0x32820dc70>, 1248740.1487453976]]\n"
     ]
    }
   ],
   "source": [
    "instructor_models = []\n",
    "for i in range(3,16,2):\n",
    "    print(f\"Training Model with N = {i}\")\n",
    "    model = N_Gram_Code_Model(i)\n",
    "    model.train_model(instructor_data, method_column=\"Method Java\")\n",
    "    # Use evaluation set to evaluate the model\n",
    "    perplexity = sum([model.get_perplexity(code) for code in evaluation_set[\"Method Java Formatted\"].array]) / len(evaluation_set)\n",
    "    instructor_models.append([model, perplexity])\n",
    "    print(f\"Perplexity: {perplexity}\\n\")\n",
    "\n",
    "instructor_models.sort(key=lambda m: m[1])\n",
    "print(instructor_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "best_instructor_model = instructor_models[0][0]\n",
    "print(best_model.N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Best Instructor and Student Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"best_student_model.pkl\", \"wb\") as file:\n",
    "    pickle.dump(best_model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"best_instructor_model.pkl\", \"wb\") as instructor_file:\n",
    "    pickle.dump(best_instructor_model, instructor_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of how to recover the two models\n",
    "with open(\"best_student_model.pkl\") as file:\n",
    "    loaded_student_model = pickle.load(file)\n",
    "with open(\"best_instructor_model.pkl\") as file:\n",
    "    loaded_instructor_model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student Perplexity: 38.86954648826244\n",
      "Instructor Perplexity: 1715719.9194230684\n"
     ]
    }
   ],
   "source": [
    "student_perplexity = sum([best_model.get_perplexity(code) for code in test_set[\"Method Java Formatted\"].array]) / len(test_set)\n",
    "instructor_perplexity = sum([best_instructor_model.get_perplexity(code) for code in test_set[\"Method Java Formatted\"].array]) / len(test_set)\n",
    "print(\"Student Perplexity:\", student_perplexity)\n",
    "print(\"Instructor Perplexity:\", instructor_perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IF TIME, CHAIN PREDICTIONS TOGETHER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIFSE_N_GRAM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
